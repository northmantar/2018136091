## 머신러닝 학습 오류 및 해결법
![image](https://user-images.githubusercontent.com/55045082/91534995-6f765100-e94d-11ea-942b-2bbc23fb77de.png)
* 학습 오류
  * 잘못된 Learning rate 설정에 의한 오류
    * Big learning rate(=Overshooting)  
    : 학습이 이뤄지지 않을 수도 있을 뿐만 아니라, cost 함수의 결과 값이 숫자가 아닌  
    값으로 출력될 수도 있다(cost를 최적화하는 과정에서 튕겨져 나가기 때문).
    * Small learning rate  
    : 학습 시간이 너무 오래 걸리고, 시간이 만료될 경우에는 global minimum이 아닌  
    local minimum에서 멈출 수 있다.
    > 해결법  
    : 적당한 Learning rate를 설정한다. 초기에 0.01 정도로 설정하여 cost가 발산한다면 조금 작게,  
    cost 변화가 너무 작다면 조금 크게 설정하여 적당한 Learning rate를 찾는다.
  * Feature data(X) 간에 크기 차이가 클 경우  
  : Learning rate를 잘 잡았음에도 불구, 학습이 일어나지 않거나 cost가 발산한다면  
  데이터 중 차이가 크게 나는 것들이 있을 수 있다.
    > 해결법  
    : 데이터를 Standardization(Normalization 중 하나)하여 전처리한다.  
![image](https://user-images.githubusercontent.com/55045082/91535659-7356a300-e94e-11ea-938c-321dbe4a897e.png)와 같이 feature data를 전처리하여 해당 오류를 해결할 수 있다.
  * Overfitting  
  : training data에 너무 잘 맞는 모델이 만들어져 test data나 실제로 사용해 봤을 때 예측이 잘 맞지 않는 경우이다.
    > 해결법
    > 1) training data의 수를 더 많게 한다.  
    > 2) 중복 feature를 제거하는 등 feature의 개수를 줄인다.  
    > 3) Regularization(일반화)  
    : weight가 너무 크면 model이 구부러지므로 일반화하여 너무 큰 weight를 가지지 않게 하는 것이다.  
    cost(=loss)에 regularization strength(![image](https://user-images.githubusercontent.com/55045082/91535732-95e8bc00-e94e-11ea-95a5-5acaab9efaff.png))를 더하여 ![image](https://user-images.githubusercontent.com/55045082/91535749-9bde9d00-e94e-11ea-9f5e-acd9f67e3699.png)와 같이 나타내어 일반화한다.
